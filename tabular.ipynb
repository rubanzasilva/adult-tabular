{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from sagemaker.content_types import CONTENT_TYPE_JSON, CONTENT_TYPE_CSV, CONTENT_TYPE_NPY\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.predictor import RealTimePredictor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import sagemaker.amazon.common as smac\n",
    "import sagemaker\n",
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch.model import PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import subprocess\n",
    "\n",
    "import PIL\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch, PyTorchModel\n",
    "from sagemaker.predictor import RealTimePredictor, json_deserializer\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import boto3\n",
    "import botocore\n",
    "#import nltk\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "import os\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/tabular'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-us-east-1-574012547351/sagemaker/tabular\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(path=path, bucket=bucket, key_prefix=prefix)\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_fastai_service.py  rossmann_sales.py  tabular-bentoml.ipynb\ttabular.ipynb\r\n",
      "__pycache__\t      source\t\t tabular_bentoml.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m#!/usr/bin/env python\u001b[39;49;00m\r\n",
      "\u001b[37m# coding: utf-8\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# In[ ]:\u001b[39;49;00m\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_containers\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrequests\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mio\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mglob\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msix\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msix\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m StringIO, BytesIO\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mfastai\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mfastai.tabular\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m *\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\r\n",
      "logger.setLevel(logging.DEBUG)\r\n",
      "\r\n",
      "\u001b[37m# set the constants for the content types\u001b[39;49;00m\r\n",
      "JSON_CONTENT_TYPE = \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "\r\n",
      "        \r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_train\u001b[39;49;00m(args):\r\n",
      "    device = \u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mDevice Type: {}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(device))\r\n",
      "\r\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading Pets dataset\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(f\u001b[33m'\u001b[39;49;00m\u001b[33mBatch size: {args.batch_size}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    path = Path(args.data_dir)\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(f\u001b[33m'\u001b[39;49;00m\u001b[33mData path is: {path}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "\r\n",
      "    \r\n",
      "    \u001b[37m# get the pattern to select the training/validation data\u001b[39;49;00m\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mCreating DataBunch object\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    df = pd.read_csv(path/\u001b[33m'\u001b[39;49;00m\u001b[33madult.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    procs = [FillMissing, Categorify, Normalize]\r\n",
      "    valid_idx = \u001b[36mrange\u001b[39;49;00m(\u001b[36mlen\u001b[39;49;00m(df)-\u001b[34m2000\u001b[39;49;00m, \u001b[36mlen\u001b[39;49;00m(df))\r\n",
      "    dep_var = \u001b[33m'\u001b[39;49;00m\u001b[33msalary\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "    cat_names = [\u001b[33m'\u001b[39;49;00m\u001b[33mworkclass\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33meducation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mmarital-status\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33moccupation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mrelationship\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mrace\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33msex\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mnative-country\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "    data = TabularDataBunch.from_df(path, df, dep_var, valid_idx=valid_idx, procs=procs, cat_names=cat_names)\r\n",
      "    learn = tabular_learner(data, layers=[\u001b[34m200\u001b[39;49;00m,\u001b[34m100\u001b[39;49;00m], emb_szs={\u001b[33m'\u001b[39;49;00m\u001b[33mnative-country\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[34m10\u001b[39;49;00m}, metrics=accuracy)\r\n",
      "    learn.fit_one_cycle(\u001b[34m1\u001b[39;49;00m, \u001b[34m1e-2\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving the model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    model_path = Path(args.model_dir)\r\n",
      "\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(f\u001b[33m'\u001b[39;49;00m\u001b[33mExport data object\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    data.export(model_path/\u001b[33m'\u001b[39;49;00m\u001b[33mexport.pkl\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[37m# create empty models dir\u001b[39;49;00m\r\n",
      "    os.mkdir(model_path/\u001b[33m'\u001b[39;49;00m\u001b[33mmodels\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(f\u001b[33m'\u001b[39;49;00m\u001b[33mSaving model weights\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m learn.save(model_path)\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\r\n",
      "    logger.info(\u001b[33m'\u001b[39;49;00m\u001b[33mmodel_fn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    path = Path(model_dir)\r\n",
      "    empty_data = TabularDataBunch.load_empty(path)\r\n",
      "    \r\n",
      "    learn = tabular_learner(empty_data, layers=[\u001b[34m200\u001b[39;49;00m,\u001b[34m100\u001b[39;49;00m] )\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m learn\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(request_body, request_content_type):\r\n",
      "    \u001b[33m\"\"\"An input_fn that loads a pickled numpy array\"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[37m# print(\"request_body=\",str(request_body))\u001b[39;49;00m\r\n",
      "    \u001b[37m# print(\"np.load(StringIO(request_body))=\",np.load(StringIO(request_body)))\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[34mif\u001b[39;49;00m request_content_type == \u001b[33m\"\u001b[39;49;00m\u001b[33mapplication/python-pickle\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\r\n",
      "        array = np.load(BytesIO((request_body)))\r\n",
      "        \u001b[37m# print(\"array=\",array)\u001b[39;49;00m\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m array\r\n",
      "    \u001b[34melif\u001b[39;49;00m request_content_type == \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "        jsondata = json.load(StringIO(request_body))\r\n",
      "        normalized_data, benchmark_data = process_input_data(jsondata)\r\n",
      "        \u001b[37m# print(\"normalized_data=\",normalized_data)\u001b[39;49;00m\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m normalized_data, benchmark_data\r\n",
      "    \u001b[34melse\u001b[39;49;00m:\r\n",
      "        \u001b[37m# Handle other content-types here or raise an Exception\u001b[39;49;00m\r\n",
      "        \u001b[37m# if the content type is not supported.\u001b[39;49;00m\r\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m{} not supported by script!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(request_content_type))\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_data, model):\r\n",
      "    device = torch.device(\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    model.to(device)\r\n",
      "    model.eval()\r\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m model(input_data.to(device))\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(prediction, accept):\r\n",
      "    \u001b[33m\"\"\"Format prediction output\u001b[39;49;00m\r\n",
      "\u001b[33m    The default accept/content-type between containers for serial inference is JSON.\u001b[39;49;00m\r\n",
      "\u001b[33m    We also want to set the ContentType or mimetype as the same value as accept so the next\u001b[39;49;00m\r\n",
      "\u001b[33m    container can read the response payload correctly.\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[34mif\u001b[39;49;00m accept == \u001b[33m\"\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m worker.Response(json.dumps(prediction), accept, mimetype=accept)\r\n",
      "    \u001b[34melif\u001b[39;49;00m accept == \u001b[33m'\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m worker.Response(encoders.encode(prediction, accept), accept, mimetype=accept)\r\n",
      "    \u001b[34melse\u001b[39;49;00m:\r\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m{} accept type is not supported by this script.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(accept))\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--workers\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m2\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mW\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of data loading workers (default: 2)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m2\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of total epochs to run (default: 2)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mBS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mbatch size (default: 4)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.001\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minitial learning rate (default: 0.001)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--momentum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.9\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, help=\u001b[33m'\u001b[39;49;00m\u001b[33mmomentum (default: 0.9)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--dist_backend\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m'\u001b[39;49;00m\u001b[33mgloo\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, help=\u001b[33m'\u001b[39;49;00m\u001b[33mdistributed backend (default: gloo)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    env = sagemaker_containers.training_env()\r\n",
      "    \r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=env.hosts)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=env.current_host)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=env.model_dir)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=env.channel_input_dirs.get(\u001b[33m'\u001b[39;49;00m\u001b[33mtraining\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--num-gpus\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=env.num_gpus)\r\n",
      "\r\n",
      "    _train(parser.parse_args())\r\n",
      "    \r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize source/rs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out all lines below if not training on SageMaker\n",
    "data_location=inputs\n",
    "instance_type = 'ml.m4.xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-12 19:59:21 Starting - Starting the training job...\n",
      "2019-10-12 19:59:23 Starting - Launching requested ML instances......\n",
      "2019-10-12 20:00:25 Starting - Preparing the instances for training...\n",
      "2019-10-12 20:01:09 Downloading - Downloading input data...\n",
      "2019-10-12 20:01:34 Training - Downloading the training image.\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2019-10-12 20:01:55,413 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[31m2019-10-12 20:01:55,416 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-10-12 20:01:55,430 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[31m2019-10-12 20:01:55,431 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\n",
      "2019-10-12 20:01:54 Training - Training image download completed. Training in progress.\u001b[31m2019-10-12 20:02:11,243 sagemaker-containers INFO     Module rs does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-10-12 20:02:11,243 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-10-12 20:02:11,243 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-10-12 20:02:11,243 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: rs\n",
      "  Running setup.py bdist_wheel for rs: started\n",
      "  Running setup.py bdist_wheel for rs: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1h4ugrqj/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built rs\u001b[0m\n",
      "\u001b[31mInstalling collected packages: rs\u001b[0m\n",
      "\u001b[31mSuccessfully installed rs-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.2.3 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-10-12 20:02:13,335 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-10-12 20:02:13,349 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"fastai-tabular-2019-10-12-19-59-20-735\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-574012547351/fastai-tabular-2019-10-12-19-59-20-735/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"rs\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"rs.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=rs.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=rs\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-us-east-1-574012547351/fastai-tabular-2019-10-12-19-59-20-735/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"fastai-tabular-2019-10-12-19-59-20-735\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-574012547351/fastai-tabular-2019-10-12-19-59-20-735/source/sourcedir.tar.gz\",\"module_name\":\"rs\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"rs.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m rs\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mBatch size: 64\u001b[0m\n",
      "\u001b[31mData path is: /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[31mCreating DataBunch object\u001b[0m\n",
      "\u001b[31mepoch     train_loss  valid_loss  accuracy\u001b[0m\n",
      "\u001b[31m1         0.325978    0.315000    0.844000  \u001b[0m\n",
      "\u001b[31mExport data object\u001b[0m\n",
      "\u001b[31mSaving model weights\u001b[0m\n",
      "\u001b[31m2019-10-12 20:02:23,274 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-10-12 20:02:30 Uploading - Uploading generated training model\n",
      "2019-10-12 20:02:30 Completed - Training job completed\n",
      "Training seconds: 81\n",
      "Billable seconds: 81\n"
     ]
    }
   ],
   "source": [
    "tabular_estimator = PyTorch(entry_point='source/rs.py',\n",
    "                         base_job_name='fastai-tabular',\n",
    "                         role=role,\n",
    "                         framework_version='1.0.0',\n",
    "                         train_instance_count=1,\n",
    "                         train_instance_type=instance_type)\n",
    "\n",
    "tabular_estimator.fit(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "import sagemaker\n",
    "class TabularPredictor(RealTimePredictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super().__init__(endpoint_name, sagemaker_session=sagemaker_session, serializer=None, \n",
    "                         deserializer=json_deserializer, content_type='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "# Uncomment out for SageMaker Deployment\n",
    "instance_type = 'ml.c5.large'\n",
    "\n",
    "tabular_model=PyTorchModel(model_data=tabular_estimator.model_data,\n",
    "                        name=tabular_estimator._current_job_name,\n",
    "                        role=role,\n",
    "                        framework_version=tabular_estimator.framework_version,\n",
    "                        entry_point=tabular_estimator.entry_point,\n",
    "                        predictor_cls=TabularPredictor)\n",
    "\n",
    "tabular_predictor = tabular_model.deploy(initial_instance_count=1,\n",
    "                                       instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_fastai_service.py  rossmann_sales.py  tabular-bentoml.ipynb\ttabular.ipynb\r\n",
      "__pycache__\t      source\t\t tabular_bentoml.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n<title>500 Internal Server Error</title>\n<h1>Internal Server Error</h1>\n<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/fastai-tabular-2019-10-12-19-59-20-735 in account 574012547351 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-f04595e0d803>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtabular_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mrequest_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_request_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n<title>500 Internal Server Error</title>\n<h1>Internal Server Error</h1>\n<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/fastai-tabular-2019-10-12-19-59-20-735 in account 574012547351 for more information."
     ]
    }
   ],
   "source": [
    "img_bytes = requests.get(url).content\n",
    "tabular_predictor.predict(img_bytes); response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"urls = []\n",
    "\n",
    "urls.append(\"http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"img_bytes = requests.get(url).content\n",
    "img = PIL.Image.open(io.BytesIO(img_bytes))\n",
    "img\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(tabular_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
